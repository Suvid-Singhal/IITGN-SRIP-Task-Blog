[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Task Blog",
    "section": "",
    "text": "Binary and Multi-Class Classification in Python\n\n\n\n\n\n\nDeep Learning\n\n\n\nThe blog post created using the jupyter notebook file and Quarto\n\n\n\n\n\nMay 22, 2021\n\n\nSuvid Singhal\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m Suvid Singhal, a first year student at BITS Pilani, Pilani campus. I’m interested in Software Development, Artificial Intelligence and Cyber Security."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/task-hosted/Task.html",
    "href": "posts/task-hosted/Task.html",
    "title": "Binary and Multi-Class Classification in Python",
    "section": "",
    "text": "I used an NVIDIA RTX 3050 for this task but the code will work on CPU as well\nFulfilled all the requirements by implementing the following: - Organized the dataset for one-vs-rest (binary) classification - Organized the dataset for 5-class classification - Performed binary classification using existing architecture (pre-trained AlexNet) - Performed 5-class classification using existing architecture (pre-trained AlexNet) - Performed binary classification using existing architecture (AlexNet trained from scratch on the given dataset) - Performed 5-class classification using existing architecture (AlexNet trained from scratch on the given dataset) - Created a custom model for binary classification and trained it on the given dataset - Created a custom model for 5-class classification and trained it on the given dataset - Used 3-fold validation for calculating the accuracies of the models - Generated classification matrices for the models and also calculated accuracy using it - Visualized the output of all the convolutional layers for different classes in the custom CNN model - Discussed my insights on the automatically created features by the custom CNN\nI was not able to upload pre-trained models on GitHub due to size limit\n\n\n\n\n\nThe directory structure should look like this: \n\n\n\nThe “animals” directory contains 90 different labels and each folder contains 60 images of each animal\nFor One-vs-Rest classification, we’ll choose bat as our positive sample\nThe following code creates the appropriate directory structure, if it does not exist.\nThis notebook must be present in the same directory as the “animal” directory for the code to work.\nSelecting 5 random images from each class to build the “others” label.\nimport os\nimport shutil\nimport random\nsrc_folder = \"animals/bat\"\nfolders = os.listdir(\"animals\")\ntemp = []\nfor folder in folders:\n    if folder != \"bat\":\n        temp.append([os.path.join(\"animals/\"+folder, file) for file in random.sample(os.listdir(\"animals/\"+folder),1)])\nto_copy=[]\nfor temp_list in temp:\n    for item in temp_list:\n        to_copy.append(item)\nif not os.path.exists(\"one-vs-rest\"):\n    shutil.copytree(src_folder, \"one-vs-rest/bat\")\n    os.mkdir(\"one-vs-rest/others\")\n    for file_name in to_copy:\n        shutil.copy2(file_name, \"one-vs-rest/others/\")\n\n\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import KFold\nimport numpy as np\n\nnum_epochs = 10\n\n# Define transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load dataset\ndataset = torchvision.datasets.ImageFolder(root='one-vs-rest/', transform=transform)\n\n# Define k-fold cross-validation\nkfold = KFold(n_splits=3, shuffle=True, random_state=42)\n\naccuracies=[]\n\nfor fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n    print(f\"Fold {fold+1}\")\n\n    # Split dataset into train and validation subsets\n    train_subset = Subset(dataset, train_idx)\n    val_subset = Subset(dataset, val_idx)\n\n    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n\n    # Load pre-trained AlexNet model\n    model = torchvision.models.alexnet(pretrained=True)\n\n    # Freeze the parameters of the pre-trained layers\n    for param in model.parameters():\n        param.requires_grad = False\n\n    # Modify the last fully connected layer for binary classification\n    num_ftrs = model.classifier[6].in_features\n    model.classifier[6] = nn.Linear(num_ftrs, 2)\n\n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    # Train the model\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n        epoch_loss = running_loss / len(train_loader.dataset)\n        print(f\"Epoch {epoch+1}/{5}, Training Loss: {epoch_loss:.4f}\")\n\n    # Evaluate the model\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    accuracy = correct / total\n    accuracies.append(accuracy)\n    print(f\"Validation Accuracy: {accuracy:.4f}\")\n\n    # Save the model\n    torch.save(model.state_dict(), f'alexnet_ovr_fold_{fold+1}.pth')\n\nprint(\"\\nFinal Mean Accuracy:\", '{0:.4f}'.format(np.mean(accuracies)))\nFold 1\n\n\nC:\\Users\\suvid\\.conda\\envs\\intern\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\nC:\\Users\\suvid\\.conda\\envs\\intern\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\nEpoch 1/5, Training Loss: 0.4932\nEpoch 2/5, Training Loss: 0.1409\nEpoch 3/5, Training Loss: 0.0635\nEpoch 4/5, Training Loss: 0.0384\nEpoch 5/5, Training Loss: 0.0199\nValidation Accuracy: 0.9625\nFold 2\nEpoch 1/5, Training Loss: 0.5235\nEpoch 2/5, Training Loss: 0.1369\nEpoch 3/5, Training Loss: 0.0816\nEpoch 4/5, Training Loss: 0.0291\nEpoch 5/5, Training Loss: 0.0238\nValidation Accuracy: 0.8861\nFold 3\nEpoch 1/5, Training Loss: 0.6815\nEpoch 2/5, Training Loss: 0.2231\nEpoch 3/5, Training Loss: 0.1060\nEpoch 4/5, Training Loss: 0.0705\nEpoch 5/5, Training Loss: 0.0449\nValidation Accuracy: 0.9620\n\nFinal Mean Accuracy: 0.9369\n#Predicting\n\nimport torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Load the trained model\nmodel = torchvision.models.alexnet(pretrained=True)\nnum_features = model.classifier[6].in_features\nmodel.classifier[6] = torch.nn.Linear(num_features, 2)\n\n# Load the saved state dictionary\nstate_dict = torch.load('alexnet_ovr_fold_1.pth')\n\n# Remove the 'module.' prefix if present (for loading from a DataParallel model)\nif 'module.' in list(state_dict.keys())[0]:\n    state_dict = {k[7:]: v for k, v in state_dict.items()}\n\n# Load the state dictionary into the model\nmodel.load_state_dict(state_dict)\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Define transforms for preprocessing the image\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load and preprocess the image\nimage_path = 'C:\\\\Users\\\\suvid\\\\Desktop\\\\fruitbat.jpg'  # Replace with the path to your image\nimage = Image.open(image_path)\nimage = image.convert(\"RGB\")\n\nimage_tensor = transform(image)\nimage_tensor = image_tensor.unsqueeze(0)  # Add batch dimension\n\n# Perform prediction\nwith torch.no_grad():\n    outputs = model(image_tensor)\n    _, predicted = torch.max(outputs, 1)\n    predicted_class = predicted.item()\n\n# Get class label\nclass_labels = ['Bat', 'Others']\npredicted_label = class_labels[predicted_class]\n\n# Visualize the image and prediction\nplt.imshow(image)\nplt.title(f'Predicted Class: {predicted_label}')\nplt.axis('off')\nplt.show()\n\n\n\n\nWe’re taking 5 labels: cat, cow, octopus, oyster and panda\nimport os\nimport shutil\nimport random\n\nif not os.path.exists(\"five-class\"):\n    shutil.copytree(\"animals/cat\", \"five-class/cat\")\n    shutil.copytree(\"animals/cow\", \"five-class/cow\")\n    shutil.copytree(\"animals/octopus\", \"five-class/octopus\")\n    shutil.copytree(\"animals/oyster\", \"five-class/oyster\")\n    shutil.copytree(\"animals/panda\", \"five-class/panda\")\n\n\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import KFold\n\n# Define transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load dataset\ndataset = torchvision.datasets.ImageFolder(root='five-class/', transform=transform)\n\n# Define k-fold cross-validation\nkfold = KFold(n_splits=3, shuffle=True, random_state=42)\n\naccuracies=[]\n\nfor fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n    print(f\"Fold {fold+1}\")\n\n    # Split dataset into train and validation subsets\n    train_subset = Subset(dataset, train_idx)\n    val_subset = Subset(dataset, val_idx)\n\n    # Create data loaders\n    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n\n    # Load pre-trained AlexNet model\n    model = torchvision.models.alexnet(pretrained=True)\n\n    # Modify the final fully connected layer for 5-class classification\n    num_ftrs = model.classifier[6].in_features\n    model.classifier[6] = nn.Linear(num_ftrs, 5)  # 5 output classes for 5-class classification\n\n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n\n    # Train the model\n    for epoch in range(5):  # Number of epochs\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n        epoch_loss = running_loss / len(train_loader.dataset)\n        print(f\"Epoch {epoch+1}/{5}, Training Loss: {epoch_loss:.4f}\")\n\n    # Evaluate the model\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    accuracy = correct / total\n    accuracies.append(accuracy)\n    print(f\"Validation Accuracy: {accuracy:.4f}\")\n\n    # Save the model\n    torch.save(model.state_dict(), f'alexnet_pretrained_5_class_fold_{fold+1}.pth')\n\nprint(\"\\nFinal Mean Accuracy:\", '{0:.4f}'.format(np.mean(accuracies)))\nFold 1\nEpoch 1/5, Training Loss: 2.0340\nEpoch 2/5, Training Loss: 1.5618\nEpoch 3/5, Training Loss: 1.2037\nEpoch 4/5, Training Loss: 0.9442\nEpoch 5/5, Training Loss: 0.7466\nValidation Accuracy: 0.8000\nFold 2\nEpoch 1/5, Training Loss: 1.8057\nEpoch 2/5, Training Loss: 1.3289\nEpoch 3/5, Training Loss: 0.9609\nEpoch 4/5, Training Loss: 0.7331\nEpoch 5/5, Training Loss: 0.5253\nValidation Accuracy: 0.8100\nFold 3\nEpoch 1/5, Training Loss: 1.7709\nEpoch 2/5, Training Loss: 1.3511\nEpoch 3/5, Training Loss: 0.9841\nEpoch 4/5, Training Loss: 0.7640\nEpoch 5/5, Training Loss: 0.5536\nValidation Accuracy: 0.7900\n\nFinal Mean Accuracy: 0.8000\n#Predicting\n\nimport torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Load the trained model\nmodel = torchvision.models.alexnet(pretrained=True)\nnum_features = model.classifier[6].in_features\nmodel.classifier[6] = torch.nn.Linear(num_features, 5)\n\n# Load the saved state dictionary\nstate_dict = torch.load('alexnet_pretrained_5_class_fold_1.pth')\n\n# Remove the 'module.' prefix if present (for loading from a DataParallel model)\nif 'module.' in list(state_dict.keys())[0]:\n    state_dict = {k[7:]: v for k, v in state_dict.items()}\n\nmodel.load_state_dict(state_dict)\n\nmodel.eval()\n\n# Define transforms for preprocessing the image\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load and preprocess the image\nimage_path = 'C:\\\\Users\\\\suvid\\\\Desktop\\\\oyster2.jpg'\nimage = Image.open(image_path)\nimage = image.convert(\"RGB\")\n\nimage_tensor = transform(image)\nimage_tensor = image_tensor.unsqueeze(0)\n\n# Perform prediction\nwith torch.no_grad():\n    outputs = model(image_tensor)\n    _, predicted = torch.max(outputs, 1)\n    predicted_class = predicted.item()\n\n# Get class label\nclass_labels = [\"Cat\", \"Cow\", \"Octopus\", \"Oyster\",\"Panda\"]\npredicted_label = class_labels[predicted_class]\n\n# Visualize the image and prediction\nplt.imshow(image)\nplt.title(f'Predicted Class: {predicted_label}')\nplt.axis('off')\nplt.show()"
  },
  {
    "objectID": "posts/task-hosted/Task.html#restructuring-for-one-vs-rest",
    "href": "posts/task-hosted/Task.html#restructuring-for-one-vs-rest",
    "title": "Binary and Multi-Class Classification in Python",
    "section": "",
    "text": "The “animals” directory contains 90 different labels and each folder contains 60 images of each animal\nFor One-vs-Rest classification, we’ll choose bat as our positive sample\nThe following code creates the appropriate directory structure, if it does not exist.\nThis notebook must be present in the same directory as the “animal” directory for the code to work.\nSelecting 5 random images from each class to build the “others” label.\nimport os\nimport shutil\nimport random\nsrc_folder = \"animals/bat\"\nfolders = os.listdir(\"animals\")\ntemp = []\nfor folder in folders:\n    if folder != \"bat\":\n        temp.append([os.path.join(\"animals/\"+folder, file) for file in random.sample(os.listdir(\"animals/\"+folder),1)])\nto_copy=[]\nfor temp_list in temp:\n    for item in temp_list:\n        to_copy.append(item)\nif not os.path.exists(\"one-vs-rest\"):\n    shutil.copytree(src_folder, \"one-vs-rest/bat\")\n    os.mkdir(\"one-vs-rest/others\")\n    for file_name in to_copy:\n        shutil.copy2(file_name, \"one-vs-rest/others/\")"
  },
  {
    "objectID": "posts/task-hosted/Task.html#using-pre-trained-existing-architecture-alexnet-for-binary-classification-one-vs-rest",
    "href": "posts/task-hosted/Task.html#using-pre-trained-existing-architecture-alexnet-for-binary-classification-one-vs-rest",
    "title": "Binary and Multi-Class Classification in Python",
    "section": "",
    "text": "import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import KFold\nimport numpy as np\n\nnum_epochs = 10\n\n# Define transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load dataset\ndataset = torchvision.datasets.ImageFolder(root='one-vs-rest/', transform=transform)\n\n# Define k-fold cross-validation\nkfold = KFold(n_splits=3, shuffle=True, random_state=42)\n\naccuracies=[]\n\nfor fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n    print(f\"Fold {fold+1}\")\n\n    # Split dataset into train and validation subsets\n    train_subset = Subset(dataset, train_idx)\n    val_subset = Subset(dataset, val_idx)\n\n    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n\n    # Load pre-trained AlexNet model\n    model = torchvision.models.alexnet(pretrained=True)\n\n    # Freeze the parameters of the pre-trained layers\n    for param in model.parameters():\n        param.requires_grad = False\n\n    # Modify the last fully connected layer for binary classification\n    num_ftrs = model.classifier[6].in_features\n    model.classifier[6] = nn.Linear(num_ftrs, 2)\n\n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    # Train the model\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n        epoch_loss = running_loss / len(train_loader.dataset)\n        print(f\"Epoch {epoch+1}/{5}, Training Loss: {epoch_loss:.4f}\")\n\n    # Evaluate the model\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    accuracy = correct / total\n    accuracies.append(accuracy)\n    print(f\"Validation Accuracy: {accuracy:.4f}\")\n\n    # Save the model\n    torch.save(model.state_dict(), f'alexnet_ovr_fold_{fold+1}.pth')\n\nprint(\"\\nFinal Mean Accuracy:\", '{0:.4f}'.format(np.mean(accuracies)))\nFold 1\n\n\nC:\\Users\\suvid\\.conda\\envs\\intern\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\nC:\\Users\\suvid\\.conda\\envs\\intern\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\nEpoch 1/5, Training Loss: 0.4932\nEpoch 2/5, Training Loss: 0.1409\nEpoch 3/5, Training Loss: 0.0635\nEpoch 4/5, Training Loss: 0.0384\nEpoch 5/5, Training Loss: 0.0199\nValidation Accuracy: 0.9625\nFold 2\nEpoch 1/5, Training Loss: 0.5235\nEpoch 2/5, Training Loss: 0.1369\nEpoch 3/5, Training Loss: 0.0816\nEpoch 4/5, Training Loss: 0.0291\nEpoch 5/5, Training Loss: 0.0238\nValidation Accuracy: 0.8861\nFold 3\nEpoch 1/5, Training Loss: 0.6815\nEpoch 2/5, Training Loss: 0.2231\nEpoch 3/5, Training Loss: 0.1060\nEpoch 4/5, Training Loss: 0.0705\nEpoch 5/5, Training Loss: 0.0449\nValidation Accuracy: 0.9620\n\nFinal Mean Accuracy: 0.9369\n#Predicting\n\nimport torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Load the trained model\nmodel = torchvision.models.alexnet(pretrained=True)\nnum_features = model.classifier[6].in_features\nmodel.classifier[6] = torch.nn.Linear(num_features, 2)\n\n# Load the saved state dictionary\nstate_dict = torch.load('alexnet_ovr_fold_1.pth')\n\n# Remove the 'module.' prefix if present (for loading from a DataParallel model)\nif 'module.' in list(state_dict.keys())[0]:\n    state_dict = {k[7:]: v for k, v in state_dict.items()}\n\n# Load the state dictionary into the model\nmodel.load_state_dict(state_dict)\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Define transforms for preprocessing the image\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load and preprocess the image\nimage_path = 'C:\\\\Users\\\\suvid\\\\Desktop\\\\fruitbat.jpg'  # Replace with the path to your image\nimage = Image.open(image_path)\nimage = image.convert(\"RGB\")\n\nimage_tensor = transform(image)\nimage_tensor = image_tensor.unsqueeze(0)  # Add batch dimension\n\n# Perform prediction\nwith torch.no_grad():\n    outputs = model(image_tensor)\n    _, predicted = torch.max(outputs, 1)\n    predicted_class = predicted.item()\n\n# Get class label\nclass_labels = ['Bat', 'Others']\npredicted_label = class_labels[predicted_class]\n\n# Visualize the image and prediction\nplt.imshow(image)\nplt.title(f'Predicted Class: {predicted_label}')\nplt.axis('off')\nplt.show()"
  },
  {
    "objectID": "posts/task-hosted/Task.html#restructuring-for-5-class-classification",
    "href": "posts/task-hosted/Task.html#restructuring-for-5-class-classification",
    "title": "Binary and Multi-Class Classification in Python",
    "section": "",
    "text": "We’re taking 5 labels: cat, cow, octopus, oyster and panda\nimport os\nimport shutil\nimport random\n\nif not os.path.exists(\"five-class\"):\n    shutil.copytree(\"animals/cat\", \"five-class/cat\")\n    shutil.copytree(\"animals/cow\", \"five-class/cow\")\n    shutil.copytree(\"animals/octopus\", \"five-class/octopus\")\n    shutil.copytree(\"animals/oyster\", \"five-class/oyster\")\n    shutil.copytree(\"animals/panda\", \"five-class/panda\")"
  },
  {
    "objectID": "posts/task-hosted/Task.html#class-classification-using-pre-trained-alexnet",
    "href": "posts/task-hosted/Task.html#class-classification-using-pre-trained-alexnet",
    "title": "Binary and Multi-Class Classification in Python",
    "section": "",
    "text": "import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import KFold\n\n# Define transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load dataset\ndataset = torchvision.datasets.ImageFolder(root='five-class/', transform=transform)\n\n# Define k-fold cross-validation\nkfold = KFold(n_splits=3, shuffle=True, random_state=42)\n\naccuracies=[]\n\nfor fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n    print(f\"Fold {fold+1}\")\n\n    # Split dataset into train and validation subsets\n    train_subset = Subset(dataset, train_idx)\n    val_subset = Subset(dataset, val_idx)\n\n    # Create data loaders\n    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n\n    # Load pre-trained AlexNet model\n    model = torchvision.models.alexnet(pretrained=True)\n\n    # Modify the final fully connected layer for 5-class classification\n    num_ftrs = model.classifier[6].in_features\n    model.classifier[6] = nn.Linear(num_ftrs, 5)  # 5 output classes for 5-class classification\n\n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n\n    # Train the model\n    for epoch in range(5):  # Number of epochs\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n        epoch_loss = running_loss / len(train_loader.dataset)\n        print(f\"Epoch {epoch+1}/{5}, Training Loss: {epoch_loss:.4f}\")\n\n    # Evaluate the model\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    accuracy = correct / total\n    accuracies.append(accuracy)\n    print(f\"Validation Accuracy: {accuracy:.4f}\")\n\n    # Save the model\n    torch.save(model.state_dict(), f'alexnet_pretrained_5_class_fold_{fold+1}.pth')\n\nprint(\"\\nFinal Mean Accuracy:\", '{0:.4f}'.format(np.mean(accuracies)))\nFold 1\nEpoch 1/5, Training Loss: 2.0340\nEpoch 2/5, Training Loss: 1.5618\nEpoch 3/5, Training Loss: 1.2037\nEpoch 4/5, Training Loss: 0.9442\nEpoch 5/5, Training Loss: 0.7466\nValidation Accuracy: 0.8000\nFold 2\nEpoch 1/5, Training Loss: 1.8057\nEpoch 2/5, Training Loss: 1.3289\nEpoch 3/5, Training Loss: 0.9609\nEpoch 4/5, Training Loss: 0.7331\nEpoch 5/5, Training Loss: 0.5253\nValidation Accuracy: 0.8100\nFold 3\nEpoch 1/5, Training Loss: 1.7709\nEpoch 2/5, Training Loss: 1.3511\nEpoch 3/5, Training Loss: 0.9841\nEpoch 4/5, Training Loss: 0.7640\nEpoch 5/5, Training Loss: 0.5536\nValidation Accuracy: 0.7900\n\nFinal Mean Accuracy: 0.8000\n#Predicting\n\nimport torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Load the trained model\nmodel = torchvision.models.alexnet(pretrained=True)\nnum_features = model.classifier[6].in_features\nmodel.classifier[6] = torch.nn.Linear(num_features, 5)\n\n# Load the saved state dictionary\nstate_dict = torch.load('alexnet_pretrained_5_class_fold_1.pth')\n\n# Remove the 'module.' prefix if present (for loading from a DataParallel model)\nif 'module.' in list(state_dict.keys())[0]:\n    state_dict = {k[7:]: v for k, v in state_dict.items()}\n\nmodel.load_state_dict(state_dict)\n\nmodel.eval()\n\n# Define transforms for preprocessing the image\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load and preprocess the image\nimage_path = 'C:\\\\Users\\\\suvid\\\\Desktop\\\\oyster2.jpg'\nimage = Image.open(image_path)\nimage = image.convert(\"RGB\")\n\nimage_tensor = transform(image)\nimage_tensor = image_tensor.unsqueeze(0)\n\n# Perform prediction\nwith torch.no_grad():\n    outputs = model(image_tensor)\n    _, predicted = torch.max(outputs, 1)\n    predicted_class = predicted.item()\n\n# Get class label\nclass_labels = [\"Cat\", \"Cow\", \"Octopus\", \"Oyster\",\"Panda\"]\npredicted_label = class_labels[predicted_class]\n\n# Visualize the image and prediction\nplt.imshow(image)\nplt.title(f'Predicted Class: {predicted_label}')\nplt.axis('off')\nplt.show()"
  },
  {
    "objectID": "posts/task-hosted/Task.html#binary-classification",
    "href": "posts/task-hosted/Task.html#binary-classification",
    "title": "Binary and Multi-Class Classification in Python",
    "section": "Binary Classification",
    "text": "Binary Classification\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import datasets\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, Subset, random_split, SubsetRandomSampler, ConcatDataset\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import KFold\n\ntorch.manual_seed(1234)\ntorch.cuda.manual_seed(1234)\nnp.random.seed(1234)\n\nData Augmentation\n# Tried to expand the dataset using data augmentation in order to improve accuracy as the dataset given was small\n\nbatch_size = 5\nnum_epochs = 15\nlearning_rate=0.001\n\nprint(torch.cuda.is_available())\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Augmentation transforms\naug_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.ToTensor(),\n])\n\n# Normal transforms\nstd_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\ndataset1 = datasets.ImageFolder('one-vs-rest/', transform=std_transform)\ndataset2 = datasets.ImageFolder('one-vs-rest/', transform=aug_transform)\ndataset = ConcatDataset([dataset1, dataset2])\ntest_dataset = dataset\nTrue\n# show random images after loading the data\n\ntrain_loader = DataLoader(dataset, batch_size=16, shuffle=True)\ntest_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n\ndef imshow(img):\n    # Unnormalize the image tensor\n    img = img * 0.229 + 0.485  # Undo normalization\n    npimg = img.numpy()\n    npimg = np.clip(npimg, 0, 1)  # clip values to stay within valid range\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n# get some random training images\ndataiter = iter(train_loader)\nimages, labels = next(dataiter)\nprint(labels)\n\n# show images\nimshow(torchvision.utils.make_grid(images))\ntensor([0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1])\n\n# Our Model for training\n\n# Experimented with batch normalization layers to improve accuracy, there is stil room for improvement in accuracy\nclass ConvNet(nn.Module):\n    def __init__(self, num_classes=1):\n        super(ConvNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2),\n            #nn.BatchNorm2d(64),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.BatchNorm2d(192),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2),\n            #nn.BatchNorm2d(192),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.BatchNorm2d(384),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            #nn.BatchNorm1d(4096),\n            nn.ReLU(inplace=True),\n            #nn.BatchNorm1d(4096),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(inplace=True),\n            \n            nn.Linear(4096, num_classes),\n            nn.Sigmoid(),\n        )\n        self.intermediate_activations = []\n\n        # Register hooks to store intermediate activations\n        for layer in self.features:\n            if isinstance(layer, nn.Conv2d):\n                layer.register_forward_hook(self.hook_fn)\n\n    def hook_fn(self, module, input, output):\n        # Store intermediate activations\n        self.intermediate_activations.append(output)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x, self.intermediate_activations\n\n\nmodel = ConvNet().to(device)\n# Our Model for getting the output of the convolutional layers\n\n# Experimented with batch normalization layers to improve accuracy, there is stil room for improvement in accuracy\nclass ConvNet(nn.Module):\n    def __init__(self, num_classes=1):\n        super(ConvNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2),\n            #nn.BatchNorm2d(64),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.BatchNorm2d(192),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2),\n            #nn.BatchNorm2d(192),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.BatchNorm2d(384),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            #nn.BatchNorm1d(4096),\n            nn.ReLU(inplace=True),\n            #nn.BatchNorm1d(4096),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(inplace=True),\n            \n            nn.Linear(4096, num_classes),\n            nn.Sigmoid(),\n        )\n        self.intermediate_activations = []\n\n        # Register hooks to store intermediate activations\n        for layer in self.features:\n            if isinstance(layer, nn.Conv2d):\n                layer.register_forward_hook(self.hook_fn)\n\n    def hook_fn(self, module, input, output):\n        # Store intermediate activations\n        self.intermediate_activations.append(output)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x, self.intermediate_activations\n\n\nmodel = ConvNet().to(device)\n# Define K-fold cross-validation\nkf = KFold(n_splits=3, shuffle=True, random_state=42)\nepochs = 10\naccuracies = []\n\n# Iterate through each fold\nfor fold, (train_index, test_index) in enumerate(kf.split(dataset)):\n    # Split the augmented dataset into train and test sets for this fold\n    train_dataset = torch.utils.data.Subset(dataset, train_index)\n    test_dataset = torch.utils.data.Subset(dataset, test_index)\n\n    # Create DataLoader for train and test sets\n    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n    \n    model = ConvNet().to(device)\n    criterion = nn.BCELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n    # Train the model\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels.float().unsqueeze(1))\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n\n        print(f'Fold {fold+1}, Epoch {epoch+1}, Training Loss: {running_loss / len(train_loader.dataset):.4f}')\n\n    # Test the model\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            predicted = (outputs &gt; 0.5).float()\n            total += labels.size(0)\n            correct += (predicted == labels.float().unsqueeze(1)).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f'Fold {fold+1}, Test Accuracy: {accuracy:.2f}%')\n    accuracies.append(accuracy)\n\n# Final accuracy\nprint(\"Final accuracy:\", np.mean(accuracies))\nFold 1, Epoch 1, Training Loss: 1.8056\nFold 1, Epoch 2, Training Loss: 0.8210\nFold 1, Epoch 3, Training Loss: 0.7612\nFold 1, Epoch 4, Training Loss: 0.7211\nFold 1, Epoch 5, Training Loss: 0.6779\nFold 1, Epoch 6, Training Loss: 0.6805\nFold 1, Epoch 7, Training Loss: 0.6489\nFold 1, Epoch 8, Training Loss: 0.7281\nFold 1, Epoch 9, Training Loss: 0.6556\nFold 1, Epoch 10, Training Loss: 0.7384\nFold 1, Test Accuracy: 66.00%\nFold 2, Epoch 1, Training Loss: 1.3068\nFold 2, Epoch 2, Training Loss: 0.8174\nFold 2, Epoch 3, Training Loss: 0.9282\nFold 2, Epoch 4, Training Loss: 0.7603\nFold 2, Epoch 5, Training Loss: 0.7085\nFold 2, Epoch 6, Training Loss: 0.7218\nFold 2, Epoch 7, Training Loss: 0.7205\nFold 2, Epoch 8, Training Loss: 0.7907\nFold 2, Epoch 9, Training Loss: 0.6886\nFold 2, Epoch 10, Training Loss: 0.6475\nFold 2, Test Accuracy: 63.64%\nFold 3, Epoch 1, Training Loss: 2.1440\nFold 3, Epoch 2, Training Loss: 0.8926\nFold 3, Epoch 3, Training Loss: 0.8780\nFold 3, Epoch 4, Training Loss: 0.6678\nFold 3, Epoch 5, Training Loss: 0.8364\nFold 3, Epoch 6, Training Loss: 0.7241\nFold 3, Epoch 7, Training Loss: 0.6923\nFold 3, Epoch 8, Training Loss: 0.7033\nFold 3, Epoch 9, Training Loss: 0.7691\nFold 3, Epoch 10, Training Loss: 0.6823\nFold 3, Test Accuracy: 66.67%\nFinal accuracy: 65.43434343434343\n# run this to save the model with best accuracy on the disk\n\ntorch.save(model.state_dict(), 'custom_cnn_binary.pth')\nimport torch\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load your model\nmodel = ConvNet()\n\n# Load the model state dictionary\nmodel_path = 'custom_cnn_binary.pth'\nmodel.load_state_dict(torch.load(model_path))\n\nmodel.eval()\n\n# Initialize lists to store true labels and predicted labels\ntrue_labels = []\npred_labels = []\n\n# Iterate over the test dataset and make predictions\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        outputs = model(inputs)\n        predicted = (outputs &gt; 0.5).float()\n        true_labels.extend(labels.cpu().numpy())\n        pred_labels.extend(predicted.cpu().numpy().flatten())\n\n# Calculate the confusion matrix\nconf_matrix = confusion_matrix(true_labels, pred_labels)\naccuracy = (conf_matrix.diagonal().sum() / conf_matrix.sum()) * 100\n\n# Plot the classification matrix using seaborn heatmap\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cbar=True)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title(f'Classification Matrix\\nAccuracy: {accuracy:.2f}%')\nplt.show()\n\nimport torch\nimport random\nimport matplotlib.pyplot as plt\n\ndef plot_grid(images, titles, prediction, actual):\n    num_images = len(images)\n    cols = min(5, num_images)\n    rows = (num_images - 1) // cols + 1\n    fig, axes = plt.subplots(rows, cols, figsize=(15, 4))\n    for i, (image, title) in enumerate(zip(images, titles)):\n        ax = axes.flatten()[i]\n        ax.imshow(image, cmap='viridis')\n        ax.set_title(title)\n        ax.axis('off')\n    plt.suptitle(f'Prediction: {prediction}\\nActual: {actual}', fontsize=16)\n    plt.show()\n\n# Load the model from disk\nmodel_path = 'custom_cnn_binary.pth'\nmodel = ConvNet()\n\nstate_dict = torch.load(model_path)\nmodel.load_state_dict(state_dict)\n\nlabels = ['Bat', 'Others']\n\n# Get input_image tensor from test dataset\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\ndata_list = list(test_loader)\n\n# Shuffle the data list to ensure randomness\nrandom.shuffle(data_list)\n\n# Iterate through the data list until a same prediction as the actual label is obtained\nfor input_image, input_label in data_list:\n    actual = labels[input_label.cpu()]\n    \n    model.eval()\n    output, intermediate_activations = model(input_image)\n    _, predicted = torch.max(output, 1)\n    prediction = labels[predicted.cpu()]\n    \n    if prediction == actual:\n        activation_images = [activation.squeeze().detach().cpu().numpy() for activation in intermediate_activations]\n        activation_images_resized = [np.mean(image, axis=0) for image in activation_images]\n        titles = [f'Conv Layer {i+1} Activation' for i in range(len(activation_images_resized))]\n\n        # Plot intermediate activations in a grid\n        plot_grid(activation_images_resized, titles, prediction, actual)\n        break\n\nimport torch\nimport random\nimport matplotlib.pyplot as plt\n\ndef plot_grid(images, titles, prediction, actual):\n    num_images = len(images)\n    cols = min(5, num_images)\n    rows = (num_images - 1) // cols + 1\n    fig, axes = plt.subplots(rows, cols, figsize=(15, 4))\n    for i, (image, title) in enumerate(zip(images, titles)):\n        ax = axes.flatten()[i]\n        ax.imshow(image, cmap='viridis')\n        ax.set_title(title)\n        ax.axis('off')\n    plt.suptitle(f'Prediction: {prediction}\\nActual: {actual}', fontsize=16)\n    plt.show()\n\n# Load the model from disk\nmodel_path = 'custom_cnn_binary.pth'\nmodel = ConvNet()\n\nstate_dict = torch.load(model_path)\nmodel.load_state_dict(state_dict)\n\nlabels = ['Bat', 'Others']\n\n# Get input_image tensor from test dataset\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\ndata_list = list(test_loader)\n\n# Shuffle the data list to ensure randomness\nrandom.shuffle(data_list)\n\n# Iterate through the data list until a same prediction as the actual label is obtained\nfor input_image, input_label in data_list:\n    actual = labels[input_label.cpu()]\n    \n    model.eval()\n    output, intermediate_activations = model(input_image)\n    _, predicted = torch.max(output, 1)\n    prediction = labels[predicted.cpu()]\n    \n    if prediction == actual:\n        activation_images = [activation.squeeze().detach().cpu().numpy() for activation in intermediate_activations]\n        activation_images_resized = [np.mean(image, axis=0) for image in activation_images]\n        titles = [f'Conv Layer {i+1} Activation' for i in range(len(activation_images_resized))]\n\n        # Plot intermediate activations in a grid\n        plot_grid(activation_images_resized, titles, prediction, actual)\n        break\n\nimport torch\nimport random\nimport matplotlib.pyplot as plt\n\ndef plot_grid(images, titles, prediction, actual):\n    num_images = len(images)\n    cols = min(5, num_images)\n    rows = (num_images - 1) // cols + 1\n    fig, axes = plt.subplots(rows, cols, figsize=(15, 4))\n    for i, (image, title) in enumerate(zip(images, titles)):\n        ax = axes.flatten()[i]\n        ax.imshow(image, cmap='viridis')\n        ax.set_title(title)\n        ax.axis('off')\n    plt.suptitle(f'Prediction: {prediction}\\nActual: {actual}', fontsize=16)\n    plt.show()\n\n# Load the model from disk\nmodel_path = 'custom_cnn_binary.pth'\nmodel = ConvNet()\n\nstate_dict = torch.load(model_path)\nmodel.load_state_dict(state_dict)\n\nlabels = ['Bat', 'Others']\n\n# Get input_image tensor from test dataset\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\ndata_list = list(test_loader)\n\n# Shuffle the data list to ensure randomness\nrandom.shuffle(data_list)\n\n# Iterate through the data list until a same prediction as the actual label is obtained\nfor input_image, input_label in data_list:\n    actual = labels[input_label.cpu()]\n    \n    model.eval()\n    output, intermediate_activations = model(input_image)\n    _, predicted = torch.max(output, 1)\n    prediction = labels[predicted.cpu()]\n    \n    if prediction == actual:\n        activation_images = [activation.squeeze().detach().cpu().numpy() for activation in intermediate_activations]\n        activation_images_resized = [np.mean(image, axis=0) for image in activation_images]\n        titles = [f'Conv Layer {i+1} Activation' for i in range(len(activation_images_resized))]\n\n        # Plot intermediate activations in a grid\n        plot_grid(activation_images_resized, titles, prediction, actual)\n        break\n&lt;Figure size 640x480 with 0 Axes&gt;\n\n\n\nDiscussing automatically created features for identification of Bat\n\nThe model identifies the head like structure between two triangular shaped wings\nHead or lower body both can work provided they are between two triangular shaped wings\nIt then focusses more on the head and then on the wings\nEventually, as we move on from one layer to another, the focus on wings also decrease, but the focus on the head increases"
  },
  {
    "objectID": "posts/task-hosted/Task.html#binary-classification-using-alexnet-architecture-not-pre-trained",
    "href": "posts/task-hosted/Task.html#binary-classification-using-alexnet-architecture-not-pre-trained",
    "title": "Binary and Multi-Class Classification in Python",
    "section": "Binary Classification Using AlexNet architecture (Not pre-trained)",
    "text": "Binary Classification Using AlexNet architecture (Not pre-trained)\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, SubsetRandomSampler\nfrom sklearn.model_selection import KFold\nfrom torchvision.models import alexnet\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Define the AlexNet architecture\nclass AlexNet(nn.Module):\n    def __init__(self, num_classes=2):\n        super(AlexNet, self).__init__()\n        self.features = alexnet().features\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# Define transformations and create dataset\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ndataset = datasets.ImageFolder('one-vs-rest/', transform=transform)\n\n# Split dataset into three folds using KFold\nkf = KFold(n_splits=3, shuffle=True, random_state=42)\n\nall_labels = []\nall_predictions = []\n\n# Step 4: Train and evaluate the model for each fold\nfor fold, (train_index, test_index) in enumerate(kf.split(dataset)):\n    train_sampler = SubsetRandomSampler(train_index)\n    test_sampler = SubsetRandomSampler(test_index)\n    train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n    test_loader = DataLoader(dataset, batch_size=32, sampler=test_sampler)\n\n    # Define model, loss function, and optimizer\n    model = AlexNet(num_classes=2)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    # Train the model\n    for epoch in range(num_epochs):\n        model.train()\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    # Evaluate the model on test data\n    model.eval()\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            all_labels.extend(labels.tolist())\n            all_predictions.extend(predicted.tolist())\n# Compute overall classification matrix\ncm = classification_matrix(all_labels, all_predictions)\n\naccuracy = (conf_matrix.diagonal().sum() / conf_matrix.sum()) * 100\n\n# Plot the classification matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d')\nplt.title(f'Classification Matrix\\nAccuracy: {accuracy:.2f}%')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()"
  },
  {
    "objectID": "posts/task-hosted/Task.html#class-classification-using-custom-cnn",
    "href": "posts/task-hosted/Task.html#class-classification-using-custom-cnn",
    "title": "Binary and Multi-Class Classification in Python",
    "section": "5-Class Classification using Custom CNN",
    "text": "5-Class Classification using Custom CNN\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import datasets\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, Subset, random_split, SubsetRandomSampler, ConcatDataset\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import KFold\n\ntorch.manual_seed(1234)\ntorch.cuda.manual_seed(1234)\nnp.random.seed(1234)\n\nData Augmentation\n# Tried to expand the dataset using data augmentation in order to improve accuracy as the dataset given was small\n\nbatch_size = 5\nnum_epochs = 15\nlearning_rate=0.001\n\nprint(torch.cuda.is_available())\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Augmentation transforms\naug_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.ToTensor(),\n])\n\n# Normal transforms\nstd_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\ndataset1 = datasets.ImageFolder('five-class/', transform=std_transform)\ndataset2 = datasets.ImageFolder('five-class/', transform=aug_transform)\ndataset = ConcatDataset([dataset1, dataset2])\ntest_dataset = dataset\nTrue\n# show random images after loading the data\n\ntrain_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n\ndef imshow(img):\n    # Unnormalize the image tensor\n    img = img * 0.229 + 0.485\n    npimg = img.numpy()\n    npimg = np.clip(npimg, 0, 1)\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n# get some random training images\ndataiter = iter(train_loader)\nimages, labels = next(dataiter)\nprint(labels)\n\n# show images\nimshow(torchvision.utils.make_grid(images))\ntensor([4, 2, 3, 3, 4, 4, 3, 4, 4, 0, 3, 0, 1, 4, 2, 4])\n\n# Our Model for training\n\n# Experimented with batch normalization layers to improve accuracy, there is stil room for improvement in accuracy\nclass ConvNet(nn.Module):\n    def __init__(self, num_classes=5):\n        super(ConvNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2),\n            #nn.BatchNorm2d(64),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.BatchNorm2d(192),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2),\n            #nn.BatchNorm2d(192),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.BatchNorm2d(384),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        self.classifier = nn.Sequential(\n            #nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(inplace=True),\n            #nn.BatchNorm1d(4096),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(inplace=True),\n            \n            nn.Linear(4096, num_classes),\n        )\n        \n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\nmodel = ConvNet().to(device)\n\n# Our Model for getting the output of the convolutional layers\n\n# Experimented with batch normalization layers to improve accuracy, there is stil room for improvement in accuracy\nclass ConvNet(nn.Module):\n    def __init__(self, num_classes=5):\n        super(ConvNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2),\n            #nn.BatchNorm2d(64),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.BatchNorm2d(192),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2),\n            #nn.BatchNorm2d(192),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.BatchNorm2d(384),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        self.classifier = nn.Sequential(\n            #nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(inplace=True),\n            #nn.BatchNorm1d(4096),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(inplace=True),\n            \n            nn.Linear(4096, num_classes),\n        )\n        \n        self.intermediate_activations = []\n\n        # Register hooks to store intermediate activations\n        for layer in self.features:\n            if isinstance(layer, nn.Conv2d):\n                layer.register_forward_hook(self.hook_fn)\n\n    def hook_fn(self, module, input, output):\n        # Store intermediate activations\n        self.intermediate_activations.append(output)\n    \n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x, self.intermediate_activations\n\nmodel = ConvNet().to(device)\n\n# Define K-fold cross-validation\nkf = KFold(n_splits=3, shuffle=True, random_state=42)\nepochs = 10\naccuracies = []\n\n# Iterate through each fold\nfor fold, (train_index, test_index) in enumerate(kf.split(dataset)):\n    # Split the augmented dataset into train and test sets for this fold\n    train_dataset = torch.utils.data.Subset(dataset, train_index)\n    test_dataset = torch.utils.data.Subset(dataset, test_index)\n\n    # Create DataLoader for train and test sets\n    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n    \n    # Define your model, loss function, and optimizer\n    model = ConvNet(num_classes=5).to(device)  # Assuming 5 output classes\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n\n    # Train the model\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            #outputs, intermediate_activations = model(inputs)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)  \n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n\n        # Print training statistics\n        print(f'Fold {fold+1}, Epoch {epoch+1}, Training Loss: {running_loss / len(train_loader.dataset):.4f}')\n\n    # Test the model\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            #outputs, intermediate_activations = model(inputs)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)  # Get the predicted class with highest probability\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f'Fold {fold+1}, Test Accuracy: {accuracy:.2f}%')\n    accuracies.append(accuracy)\n\n# Final accuracy\nprint(\"Final accuracy:\", np.mean(accuracies))\nFold 1, Epoch 1, Training Loss: 1.5476\nFold 1, Epoch 2, Training Loss: 1.2713\nFold 1, Epoch 3, Training Loss: 1.0316\nFold 1, Epoch 4, Training Loss: 0.9983\nFold 1, Epoch 5, Training Loss: 0.9220\nFold 1, Epoch 6, Training Loss: 0.8885\nFold 1, Epoch 7, Training Loss: 0.8359\nFold 1, Epoch 8, Training Loss: 0.7286\nFold 1, Epoch 9, Training Loss: 0.8208\nFold 1, Epoch 10, Training Loss: 0.7024\nFold 1, Test Accuracy: 56.00%\nFold 2, Epoch 1, Training Loss: 1.6129\nFold 2, Epoch 2, Training Loss: 1.1900\nFold 2, Epoch 3, Training Loss: 1.0651\nFold 2, Epoch 4, Training Loss: 0.9705\nFold 2, Epoch 5, Training Loss: 0.9372\nFold 2, Epoch 6, Training Loss: 0.8511\nFold 2, Epoch 7, Training Loss: 0.7492\nFold 2, Epoch 8, Training Loss: 0.7628\nFold 2, Epoch 9, Training Loss: 0.7357\nFold 2, Epoch 10, Training Loss: 0.6575\nFold 2, Test Accuracy: 59.00%\nFold 3, Epoch 1, Training Loss: 1.5582\nFold 3, Epoch 2, Training Loss: 1.1821\nFold 3, Epoch 3, Training Loss: 1.0665\nFold 3, Epoch 4, Training Loss: 1.0389\nFold 3, Epoch 5, Training Loss: 0.8886\nFold 3, Epoch 6, Training Loss: 0.8919\nFold 3, Epoch 7, Training Loss: 0.8593\nFold 3, Epoch 8, Training Loss: 0.8592\nFold 3, Epoch 9, Training Loss: 0.8539\nFold 3, Epoch 10, Training Loss: 0.7271\nFold 3, Test Accuracy: 59.50%\nFinal accuracy: 58.166666666666664\n# run this to save the model with best accuracy on the disk\ntorch.save(model.state_dict(), 'custom_cnn_5_class.pth')\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nnum_classes = 5\n\n# Initialize the model\nmodel = ConvNet(num_classes).to(device)\nmodel.load_state_dict(torch.load('custom_cnn_5_class.pth'))\nmodel.eval()\n\ntrue_labels = []\npred_labels = []\n\n# Iterate over the test dataset and make predictions\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        true_labels.extend(labels.cpu().numpy())\n        pred_labels.extend(predicted.cpu().numpy())\n\n# Calculate the classification matrix\nconf_matrix = confusion_matrix(true_labels, pred_labels)\n\n# Calculate accuracy using the classification matrix\naccuracy = (np.diag(conf_matrix).sum() / conf_matrix.sum()) * 100\n\n# Plot the classification matrix using seaborn heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True,fmt='d', cbar=True)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title(f'Classification Matrix\\nAccuracy: {accuracy:.2f}%')\nplt.show()"
  },
  {
    "objectID": "posts/task-hosted/Task.html#visualizing-output-of-cnn-layers-and-looking-for-automatically-created-features",
    "href": "posts/task-hosted/Task.html#visualizing-output-of-cnn-layers-and-looking-for-automatically-created-features",
    "title": "Binary and Multi-Class Classification in Python",
    "section": "Visualizing Output of CNN Layers and looking for Automatically created Features",
    "text": "Visualizing Output of CNN Layers and looking for Automatically created Features\nimport torch\nimport random\nimport matplotlib.pyplot as plt\n\ndef plot_grid(images, titles, rows, cols, prediction, actual):\n    fig, axes = plt.subplots(rows, cols, figsize=(15, 4))\n    for i, (image, title) in enumerate(zip(images, titles)):\n        ax = axes.flatten()[i]\n        ax.imshow(image, cmap='viridis')\n        ax.set_title(title)\n        ax.axis('off')\n    plt.suptitle(f'Prediction: {prediction}\\nActual: {actual}',fontsize=16)\n    plt.show()\n\n# Load the model from disk\nmodel_path = 'custom_cnn_5_class.pth'\nmodel = ConvNet()\n\n# Load the state dictionary of the model\nstate_dict = torch.load(model_path)\n\n# Load the state dictionary into the model\nmodel.load_state_dict(state_dict)\nlabels=['Cat','Cow','Octopus','Oyster','Panda']\n# Get input_image tensor from test dataset\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\ndata_list = list(test_loader)\n\n# Get a random item from the list\nrandom_item = random.choice(data_list)\n\n# Extract image and label from the random item\ninput_image, input_label = random_item\nactual = labels[input_label.cpu()]\n\nmodel.eval()\noutput, intermediate_activations = model(input_image)\n_, predicted = torch.max(output, 1)\nprediction = labels[predicted.cpu()]\nwhile prediction != actual:\n    # Get a random item from the list\n    random_item = random.choice(data_list)\n    \n    # Extract image and label from the random item\n    input_image, input_label = random_item\n    actual = labels[input_label.cpu()]\n    \n    output, intermediate_activations = model(input_image)\n    _, predicted = torch.max(output, 1)\n    prediction = labels[predicted.cpu()]\n    \n# Resize activation maps to a square shape for plotting\nactivation_images = [activation.squeeze().detach().cpu().numpy() for activation in intermediate_activations]\nactivation_images_resized = [np.mean(image, axis=0) for image in activation_images]  # Compute channel-wise mean\ntitles = [f'Conv Layer {i+1} Activation' for i in range(len(activation_images_resized))]\n\n# Plot intermediate activations in a grid\nplot_grid(activation_images_resized, titles, 1, 5, prediction, actual)\n\nimport torch\nimport random\nimport matplotlib.pyplot as plt\n\ndef plot_grid(images, titles, rows, cols, prediction, actual):\n    fig, axes = plt.subplots(rows, cols, figsize=(15, 4))\n    for i, (image, title) in enumerate(zip(images, titles)):\n        ax = axes.flatten()[i]\n        ax.imshow(image, cmap='viridis')\n        ax.set_title(title)\n        ax.axis('off')\n    plt.suptitle(f'Prediction: {prediction}\\nActual: {actual}',fontsize=16)\n    plt.show()\n\n# Load the model from disk\nmodel_path = 'custom_cnn_5_class.pth'\nmodel = ConvNet()\n\n# Load the state dictionary of the model\nstate_dict = torch.load(model_path)\n\n# Load the state dictionary into the model\nmodel.load_state_dict(state_dict)\nlabels=['Cat','Cow','Octopus','Oyster','Panda']\n# Get input_image tensor from test dataset\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\ndata_list = list(test_loader)\n\n# Get a random item from the list\nrandom_item = random.choice(data_list)\n\n# Extract image and label from the random item\ninput_image, input_label = random_item\nactual = labels[input_label.cpu()]\n\nmodel.eval()\noutput, intermediate_activations = model(input_image)\n_, predicted = torch.max(output, 1)\nprediction = labels[predicted.cpu()]\nwhile prediction != actual:\n    # Get a random item from the list\n    random_item = random.choice(data_list)\n    \n    # Extract image and label from the random item\n    input_image, input_label = random_item\n    actual = labels[input_label.cpu()]\n    \n    output, intermediate_activations = model(input_image)\n    _, predicted = torch.max(output, 1)\n    prediction = labels[predicted.cpu()]\n    \n# Resize activation maps to a square shape for plotting\nactivation_images = [activation.squeeze().detach().cpu().numpy() for activation in intermediate_activations]\nactivation_images_resized = [np.mean(image, axis=0) for image in activation_images]  # Compute channel-wise mean\ntitles = [f'Conv Layer {i+1} Activation' for i in range(len(activation_images_resized))]\n\n# Plot intermediate activations in a grid\nplot_grid(activation_images_resized, titles, 1, 5, prediction, actual)\n\n\nDiscussing automatically created features for identification of Panda\n\nThe model identifies the head and body\nIt identified facial features in the first layer such as eyes shaped as panda, nose, mputh and ears\nAs we proceed in layers, the focus on head and body increases and facial features are disappeared\n\nimport torch\nimport random\nimport matplotlib.pyplot as plt\n\ndef plot_grid(images, titles, rows, cols, prediction, actual):\n    fig, axes = plt.subplots(rows, cols, figsize=(15, 4))\n    for i, (image, title) in enumerate(zip(images, titles)):\n        ax = axes.flatten()[i]\n        ax.imshow(image, cmap='viridis')\n        ax.set_title(title)\n        ax.axis('off')\n    plt.suptitle(f'Prediction: {prediction}\\nActual: {actual}',fontsize=16)\n    plt.show()\n\n# Load the model from disk\nmodel_path = 'custom_cnn_5_class.pth'\nmodel = ConvNet()\n\n# Load the state dictionary of the model\nstate_dict = torch.load(model_path)\n\n# Load the state dictionary into the model\nmodel.load_state_dict(state_dict)\nlabels=['Cat','Cow','Octopus','Oyster','Panda']\n# Get input_image tensor from test dataset\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\ndata_list = list(test_loader)\n\n# Get a random item from the list\nrandom_item = random.choice(data_list)\n\n# Extract image and label from the random item\ninput_image, input_label = random_item\nactual = labels[input_label.cpu()]\n\nmodel.eval()\noutput, intermediate_activations = model(input_image)\n_, predicted = torch.max(output, 1)\nprediction = labels[predicted.cpu()]\nwhile prediction != actual:\n    # Get a random item from the list\n    random_item = random.choice(data_list)\n    \n    # Extract image and label from the random item\n    input_image, input_label = random_item\n    actual = labels[input_label.cpu()]\n    \n    output, intermediate_activations = model(input_image)\n    _, predicted = torch.max(output, 1)\n    prediction = labels[predicted.cpu()]\n    \n# Resize activation maps to a square shape for plotting\nactivation_images = [activation.squeeze().detach().cpu().numpy() for activation in intermediate_activations]\nactivation_images_resized = [np.mean(image, axis=0) for image in activation_images]  # Compute channel-wise mean\ntitles = [f'Conv Layer {i+1} Activation' for i in range(len(activation_images_resized))]\n\n# Plot intermediate activations in a grid\nplot_grid(activation_images_resized, titles, 1, 5, prediction, actual)\n\n\n\nDiscussing automatically created features for identification of Octopus\n\nThe model identifies the head and tentacles\nThe focus in more on head like structure between or near tentacles connected to the it\nAs we proceed in layers, the focus on head also reduces a bit\n\nimport torch\nimport random\nimport matplotlib.pyplot as plt\n\ndef plot_grid(images, titles, rows, cols, prediction, actual):\n    fig, axes = plt.subplots(rows, cols, figsize=(15, 4))\n    for i, (image, title) in enumerate(zip(images, titles)):\n        ax = axes.flatten()[i]\n        ax.imshow(image, cmap='viridis')\n        ax.set_title(title)\n        ax.axis('off')\n    plt.suptitle(f'Prediction: {prediction}\\nActual: {actual}',fontsize=16)\n    plt.show()\n\n# Load the model from disk\nmodel_path = 'custom_cnn_5_class.pth'\nmodel = ConvNet()\n\n# Load the state dictionary of the model\nstate_dict = torch.load(model_path)\n\n# Load the state dictionary into the model\nmodel.load_state_dict(state_dict)\nlabels=['Cat','Cow','Octopus','Oyster','Panda']\n# Get input_image tensor from test dataset\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\ndata_list = list(test_loader)\n\n# Get a random item from the list\nrandom_item = random.choice(data_list)\n\n# Extract image and label from the random item\ninput_image, input_label = random_item\nactual = labels[input_label.cpu()]\n\nmodel.eval()\noutput, intermediate_activations = model(input_image)\n_, predicted = torch.max(output, 1)\nprediction = labels[predicted.cpu()]\nwhile prediction != actual:\n    # Get a random item from the list\n    random_item = random.choice(data_list)\n    \n    # Extract image and label from the random item\n    input_image, input_label = random_item\n    actual = labels[input_label.cpu()]\n    \n    output, intermediate_activations = model(input_image)\n    _, predicted = torch.max(output, 1)\n    prediction = labels[predicted.cpu()]\n    \n# Resize activation maps to a square shape for plotting\nactivation_images = [activation.squeeze().detach().cpu().numpy() for activation in intermediate_activations]\nactivation_images_resized = [np.mean(image, axis=0) for image in activation_images]  # Compute channel-wise mean\ntitles = [f'Conv Layer {i+1} Activation' for i in range(len(activation_images_resized))]\n\n# Plot intermediate activations in a grid\nplot_grid(activation_images_resized, titles, 1, 5, prediction, actual)\n\n\n\nDiscussing automatically created features for identification of Oyster\n\nThe model identifies the spaces in between and looks for oyster-like shape\nIt looks for slot like structures\nIt then focusses on the actual oyster more, eliminating the background\n\nimport torch\nimport random\nimport matplotlib.pyplot as plt\n\ndef plot_grid(images, titles, rows, cols, prediction, actual):\n    fig, axes = plt.subplots(rows, cols, figsize=(15, 4))\n    for i, (image, title) in enumerate(zip(images, titles)):\n        ax = axes.flatten()[i]\n        ax.imshow(image, cmap='viridis')\n        ax.set_title(title)\n        ax.axis('off')\n    plt.suptitle(f'Prediction: {prediction}\\nActual: {actual}',fontsize=16)\n    plt.show()\n\n# Load the model from disk\nmodel_path = 'custom_cnn_5_class.pth'\nmodel = ConvNet()\n\n# Load the state dictionary of the model\nstate_dict = torch.load(model_path)\n\n# Load the state dictionary into the model\nmodel.load_state_dict(state_dict)\nlabels=['Cat','Cow','Octopus','Oyster','Panda']\n# Get input_image tensor from test dataset\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\ndata_list = list(test_loader)\n\n# Get a random item from the list\nrandom_item = random.choice(data_list)\n\n# Extract image and label from the random item\ninput_image, input_label = random_item\nactual = labels[input_label.cpu()]\n\nmodel.eval()\noutput, intermediate_activations = model(input_image)\n_, predicted = torch.max(output, 1)\nprediction = labels[predicted.cpu()]\nwhile prediction != actual:\n    # Get a random item from the list\n    random_item = random.choice(data_list)\n    \n    # Extract image and label from the random item\n    input_image, input_label = random_item\n    actual = labels[input_label.cpu()]\n    \n    output, intermediate_activations = model(input_image)\n    _, predicted = torch.max(output, 1)\n    prediction = labels[predicted.cpu()]\n    \n# Resize activation maps to a square shape for plotting\nactivation_images = [activation.squeeze().detach().cpu().numpy() for activation in intermediate_activations]\nactivation_images_resized = [np.mean(image, axis=0) for image in activation_images]  # Compute channel-wise mean\ntitles = [f'Conv Layer {i+1} Activation' for i in range(len(activation_images_resized))]\n\n# Plot intermediate activations in a grid\nplot_grid(activation_images_resized, titles, 1, 5, prediction, actual)\n\n\n\nDiscussing automatically created features for identification of Cat\n\nThe model identifies the and the eyes, nose etc. (facial features) first\nIt then focusses more on the head and jaw\nEventually, as we move on from one layer to another, the focus on the head increases"
  },
  {
    "objectID": "posts/task-hosted/Task.html#binary-classification-using-alexnet-not-pre-trained",
    "href": "posts/task-hosted/Task.html#binary-classification-using-alexnet-not-pre-trained",
    "title": "Binary and Multi-Class Classification in Python",
    "section": "Binary Classification using AlexNet (not pre-trained)",
    "text": "Binary Classification using AlexNet (not pre-trained)\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, SubsetRandomSampler\nfrom sklearn.model_selection import KFold\nfrom torchvision.models import alexnet\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nnum_epochs = 10\n\n# Define the AlexNet architecture\nclass AlexNet(nn.Module):\n    def __init__(self, num_classes=5):\n        super(AlexNet, self).__init__()\n        self.features = alexnet().features\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# Define transformations and create dataset\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Update dataset directory to your 5-class dataset directory\ndataset = datasets.ImageFolder('five-class/', transform=transform)\n\n# Split dataset into three folds using KFold\nkf = KFold(n_splits=3, shuffle=True, random_state=42)\n\nall_labels = []\nall_predictions = []\nall_accuracies = []\n\n# Train and evaluate the model for each fold\nfor fold, (train_index, test_index) in enumerate(kf.split(dataset)):\n    train_sampler = SubsetRandomSampler(train_index)\n    test_sampler = SubsetRandomSampler(test_index)\n    train_loader = DataLoader(dataset, batch_size=16, sampler=train_sampler)\n    test_loader = DataLoader(dataset, batch_size=16, sampler=test_sampler)\n\n    # Define model, loss function, and optimizer\n    model = AlexNet().to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n    # Training loop\n    for epoch in range(num_epochs):  # You need to define num_epochs\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n        print(f'Fold {fold+1}, Epoch {epoch+1}, Training Loss: {running_loss / len(train_loader.dataset):.4f}')\n\n    # Evaluate the model on test data after training\n    model.eval()\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            all_labels.extend(labels.tolist())\n            all_predictions.extend(predicted.tolist())\n    \n    # Calculate accuracy for the current fold\n    accuracy = accuracy_score(all_labels, all_predictions)\n    all_accuracies.append(accuracy)\n    print(f'Fold [{fold + 1}] Accuracy: {accuracy:.4f}')\n\n# Calculate final accuracy across all folds\nfinal_accuracy = np.mean(all_accuracies)\nprint(f'Final Accuracy: {final_accuracy:.4f}')\nFold 1, Epoch 1, Training Loss: 1.0693\nFold 1, Epoch 2, Training Loss: 1.0204\nFold 1, Epoch 3, Training Loss: 0.9608\nFold 1, Epoch 4, Training Loss: 0.8554\nFold 1, Epoch 5, Training Loss: 0.9104\nFold 1, Epoch 6, Training Loss: 0.8728\nFold 1, Epoch 7, Training Loss: 0.7820\nFold 1, Epoch 8, Training Loss: 0.7446\nFold 1, Epoch 9, Training Loss: 0.6400\nFold 1, Epoch 10, Training Loss: 0.6361\nFold [1] Accuracy: 0.3800\nFold 2, Epoch 1, Training Loss: 1.0755\nFold 2, Epoch 2, Training Loss: 1.0533\nFold 2, Epoch 3, Training Loss: 1.0308\nFold 2, Epoch 4, Training Loss: 0.9636\nFold 2, Epoch 5, Training Loss: 0.8872\nFold 2, Epoch 6, Training Loss: 0.8367\nFold 2, Epoch 7, Training Loss: 0.8187\nFold 2, Epoch 8, Training Loss: 0.9069\nFold 2, Epoch 9, Training Loss: 0.7060\nFold 2, Epoch 10, Training Loss: 0.6765\nFold [2] Accuracy: 0.4600\nFold 3, Epoch 1, Training Loss: 1.0750\nFold 3, Epoch 2, Training Loss: 1.0664\nFold 3, Epoch 3, Training Loss: 1.0445\nFold 3, Epoch 4, Training Loss: 0.9687\nFold 3, Epoch 5, Training Loss: 0.9161\nFold 3, Epoch 6, Training Loss: 0.8616\nFold 3, Epoch 7, Training Loss: 0.8181\nFold 3, Epoch 8, Training Loss: 0.8172\nFold 3, Epoch 9, Training Loss: 0.7912\nFold 3, Epoch 10, Training Loss: 0.6597\nFold [3] Accuracy: 0.4967\nFinal Accuracy: 0.4456\n# Calculate and plot confusion matrix\nconf_matrix = confusion_matrix(all_labels, all_predictions)\n\n# Calculate accuracy using the classification matrix\naccuracy = (np.diag(conf_matrix).sum() / conf_matrix.sum()) * 100\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cbar=True)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title(f'Classification Matrix\\nAccuracy: {accuracy:.2f}%')\nplt.show()"
  }
]